---
title: "PROJET 1 : Caract√©ristiques des rendements logarithmiques des actions"
author: "Alexandra"
date: "2024-11-16"
output: 
  rmdformats::readthedown
---

Ce document RMarkdown a pour objectif d'apporter une explication approfondie des raisonnements et des interpr√©tations r√©alis√©s dans le cadre de l'√©tude des caract√©ristiques des rendements logarithmiques des actions, en se concentrant particuli√®rement sur les s√©ries temporelles `rte` et `rtt`.

```{r, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(xts)
library(forecast)
library(moments)
library(yfR)
library(scales)
library(FinTS)
library(fGarch)
library(TSA)
library(lmtest)
library(tseries)
library(urca)
library(CADFtest)
library(knitr)
```

```{r, include = FALSE}
my_ticker <- 'SQNXF'      
first_date <- "2013-01-01"  
last_date <-"2024-10-16"   

# fetch data
df_yf <- yf_get(tickers = my_ticker, 
                first_date = first_date,
                last_date = last_date,
                freq_data='daily',type_return='log')

pt<-df_yf$price_adjusted
dpt=diff(pt)
datesp<-df_yf$ref_date
dates<-datesp[-1]
rt=df_yf$ret_adjusted_prices[-1]
N<-length(rt)
rte<-rt[1:1761] # dates[1762] = "2020-01-02"
T<-length(rte)
rtt<-rt[1762:N]
T2<-length(rtt)
```

```{r, echo=FALSE}
datesp<-df_yf$ref_date
first_day_of_year = NULL
for (i in 1:12) {
  first_day_of_year[i] = as.character(datesp[format(datesp, "%Y") == 2012+i][1])
}

plot(datesp, pt, type='l', ylab="Cours de Square Enix (‚Ç¨)", xlab="Temps", cex.main=1.5, main="Evolution du cours de l'action Square Enix", xaxt = "n")

axis(side = 1, at=as.Date(first_day_of_year), labels=format(as.Date(first_day_of_year), "%Y"))

fit0 = lm(pt ~ datesp)
abline(fit0, col="red")


op<-par(mfrow=c(3,1))
plot(datesp,pt,type='l',ylab="indice SQNXF",col=3)
plot(dates,dpt,type='l',col=2,ylab="variations de SQNXF")
plot(dates,rt,type='l',col=1,ylab="rendement de SQNXF")
```

- Le premier graphique, montre que la s√©rie de l‚Äôaction SQNXF a une tendance croissante ;

- Les deux autres graphiques, montrent que ses variations et son rendement logarithmique fluctuent autour de 0 ;

- De plus, pour dpt les fluctuations autour de 0 augmentent dans le temps, il semble y avoir plusieurs clusters de volatilit√© de 2020 √† 2021 ainsi qu‚Äôen 2014.


# √âtude des 8 caract√©ristiques la s√©rie rte

Voici le chronogramme de la s√©rie `rte` : 

```{r, echo=FALSE}
# Supposons que rte soit d√©j√† au format s√©rie temporelle
plot(rte, main = "Chronogramme de la s√©rie rte", xlab = "Temps", ylab = "Rendements", col = "#A4163E", type = "l")
```

La s√©rie `rte` n'a visuellement pas l'air d'avoir de tendance, elle fluctue autour de 0. De plus, la variance ne semble pas non plus varier au cours du temps, mis √† part le pic se situant aux alentours de la position 250 (sans doute pr√©sence d'h√©t√©rosc√©dasticit√©).

## Propri√©t√© 1 : Asym√©trie perte / gain

### Hypoth√®ses

$H_0 : E\left[\left(\frac{X - E(X)}{\sigma_X}\right)^3\right] = 0 \quad VS \quad H_a : E\left[\left(\frac{X - E(X)}{\sigma_X}\right)^3\right] \neq 0$

### Cas pratique

```{r, echo=FALSE}
agostino.test(rte)
```

Le coefficient du skewness est significatif puisque la p-value √©tant `< 2.2e-16` est inf√©rieur 0.05 on rejette donc H0. Alors nous pouvons interpr√©ter sa valeur calcul√©e. La skewness est sup√©rieur √† 0, donc **la probabilit√© de gains est inf√©rieur √† la probabilit√© de pertes**.

## Propri√©t√© 2 : Queues de distribution √©paisses

### Hypoth√®ses

$H_0 : E\left[\left(\frac{X - E(X)}{\sigma_X}\right)^4\right] = 3 \quad VS \quad H_a : E\left[\left(\frac{X - E(X)}{\sigma_X}\right)^4\right] \neq 3$

### Cas pratique

```{r, echo=FALSE}
anscombe.test(rte)
```

La p-value du test d‚ÄôAnscombe √©tant `< 2.2e-16` est inf√©rieur  √† 0.05 on rejette H0, ce qui indique que le kurtosis est significatif. Celui-ci vaut `38` ce qui est sup√©rieur √† 3 la distribution est donc **leptokurtique**. Ainsi, **les queues de distribution sont plus √©paisses que celles d‚Äôune loi normale centr√©e r√©duite**.

## Propri√©t√© 3 : Autocorr√©lations des carr√©s des rendements fortes et faibles pour les rendements

### R√©alisation de l'ACF et de la PACF

```{r, echo=FALSE}
op<-par(mfrow=c(2,2))
Acf(rte,main="ACF du rendement logarithmique") 
Pacf(rte,main="PACF du rendement logarithmique") 
Acf(rte^2,main="ACF du rendement logarithmique au carr√©") 
Pacf(rte^2,main="PACF du rendement logarithmique au carr√©")
```

Lorsque nous observons l'ACF et la PACF de notre s√©rie `rte` comme convenu une faible autocorr√©lation √† l'ordre 7 dans les rendements, avec une valeur d‚Äôautocorr√©lation d'√† peu pr√®s 0,055.

Pour la s√©rie associ√©e aux carr√©es des rendements, l‚ÄôACF et le PACF montre une forte autocorr√©lation √† l'ordre 1 (de 0.23) mais aussi des faibles autocorr√©lation aux ordres 7 et 32, avec des valeurs respectives d'√† peu pr√®s 0.055 et 0.06.

### R√©alisation de la statistique de Ljung-Box

#### Hypoth√®ses

$H0 ‚à∂ \rho(k) = 0$ pour k = 1 jusqu‚Äô√† K $\quad VS \quad H_a : \rho(k) \neq 0$ pour au moins une valeur de k comprise entre 1 et K

#### Cas pratique

##### ‚Ä¢ Autocorr√©lations des carr√©s des rendements rte^2

```{r, echo=FALSE}
pvaluesrt =rep(0,20)
pvaluesrt2 =rep(0,20)
for (i in 1:25 ) {
  pvaluesrt[i] = Box.test(rte,lag=i,type="Ljung-Box")$p.value
  pvaluesrt2[i] = Box.test(rte^2,lag=i,type="Ljung-Box")$p.value
}

pvaluesrt2
```

Toutes les p-values sont inf√©rieures √† 0.05 et pour certaines quasiment nulle pour la s√©rie `rte^2`. On rejette donc H0 et on conclut √† la **pr√©sence d‚Äôautocorr√©lation dans 
les rendements au carr√©**.

##### ‚Ä¢ Autocorr√©lations des rendements rte

```{r, echo=FALSE}
pvaluesrt
```

Toutes les p-values sont sup√©rieurs √† 0.05 pour `rte`. On accepte donc H0 et on conclut qu'**il n'y a pas d'autocorr√©lation dans les rendements**.

Nous n'avons donc pas besoin de mod√©liser cette caract√©ristique en utilisant un mod√®le ARMA(p,q).

## Propri√©t√© 4 : Clusters de volatilit√©

### Hypoth√®ses

$H0 ‚à∂ \alpha1 = \alpha2 = ... = \alpha m = 0$ donc homosc√©dasticit√© conditionnelle 

$VS$

$Ha ‚à∂ \alpha i \neq 0$ avec $i \neq 0$ donc h√©t√©rosc√©dasticit√© conditionnelle.

**_RAPPEL :_** Une serie h√©t√©rosc√©dastique dont la variabilit√© change au cours du temps de fa√ßon non √©vidente.

### Cas pratique

```{r, echo=FALSE}
LM1<-ArchTest(as.numeric(rte),lag=1)
LM1
```

La p-value est `< 2.2e-16` ce qui est inf√©rieur √† 0.05, on rejette donc H0 et donc il y a pr√©sence de clusters de volatilit√© √† l‚Äôordre 1 dans `rte`. 

```{r, echo=FALSE}
LM2<-ArchTest(as.numeric(rte),lag=2)
LM2
```

La p-value `< 2.2e-16` ce qui est inf√©rieur √† 0.05, on rejette donc H0 et donc il y a pr√©sence de clusters de volatilit√© √† l‚Äôordre 2 dans `rte`.

```{r, echo=FALSE}
LM20<-ArchTest(as.numeric(rte),lag=20)
LM20
```

La p-value est de `4.953e-14` ce qui est inf√©rieur √† 0.05, on rejette donc H0. Il y a pr√©sence de clusters de volatilit√© √† l'ordre 20 dans `rte`.

```{r, echo=FALSE}
LM30<-ArchTest(as.numeric(rte),lag=30)
LM30
```

M√™me conclusion √† l'ordre 30. Les p-values sont donc toutes inf√©rieures √† 0.05. On rejette alors l'hypoth√®se nulle,  d‚Äôhomosc√©dasticit√© conditionnelle. **Il y a donc des clusters de volatilit√© dans la s√©rie `rte`**.

## Propri√©t√© 5 : Queues √©paisses conditionnelles

Le but de cette propri√©t√© est de mod√©liser les clusters de volatilit√© de notre s√©rie, pour cela, nous estimons un mod√®le GARCH(1,1) sur notre s√©rie `rte` normalis√©e.

```{r, echo=FALSE}
rte_centre = (rte-mean(rte))/sd(rte)
volat<-garch(rte_centre,order=c(1,1))
```

En proc√©dant de cette mani√®re, nous obtenons l'information `FALSE CONVERGENCE`. Pour rem√©dier √† cela, nous utilisons la fonction GarchFit :

```{r, echo=FALSE}
volat2=garchFit(rte_centre ~ garch(1,1), data=rte, trace=F, include.mean = F)
summary(volat2)
```

Nous avons enlev√© la constante car sa p-value √©tait sup√©rieur √† 0.05.


> Dans le cas o√π nous effectuerions l'ArchTest directement sur `volat2@residuals` (qui pr√©sente de l'autocorr√©lation) nous rencontrons des effets ARCH qu'il n'est impossible d'√©viter. Dans ce cas-l√†, nous ne pouvons ni conclure ni effectuer l'`anscombe.test`.

Apr√®s quelque recherche personnelle, j'ai tout de m√™me pris l'initiative de normalis√© les r√©sidus afin de ne plus avoir d'autocorr√©lation : 

```{r, echo=FALSE}
# On normalise les r√©sidus
res = residuals(volat2, standardize = T)
acf(res)
```

Nous pouvons d√©sormais effectuer les ArchTest :

```{r}
ArchTest(res, lag=1)
```

```{r}
ArchTest(res, lag=20)
```

```{r}
ArchTest(res, lag=30)
```

Les p-value √©tant toutes sup√©rieurs √† 0.05, nous pouvons rejeter l'hypoth√®se nulle. Le mod√®le GARCH(1,1) a r√©ussi √† prendre en compte toute l‚Äôh√©t√©rosc√©dasticit√© conditionnelle. **Il n'y a donc pas d'effet ARCH**.

**_NOTE:_** Dans le cadre o√π nous aurions gard√© `volat2@residuals` nous n'aurions pas pu enlever les effets ARCH et nous n'aurons pas pu conclure et faire l'√©tape suivante. 

Maintenant, on cherche √† voir si les queues de distribution des al√©as de notre ARMA-GARCH sont plus √©paisses que celles d‚Äôune loi normale.

$H0 ‚à∂$ kurtosis $= 3 \quad VS \quad Ha :$ kurtosis $\neq 3$

```{r, echo=FALSE}
anscombe.test(res)
```

On trouve une p-value `< 2.2e-16` donc on rejette H0. De plus le kurtosis est de 38 > 3. Ainsi **les queues de distribution des al√©as de notre ARMA-GARCH sont plus √©paisses que celles d‚Äôune loi normale**.

## Propri√©t√© 6 : Effet de levier

```{r, echo=FALSE}
sig<-rep(0,T)
for(t in 1:T) {
  sig[t]<-sqrt(sum(rte[t-22]-(sum(rte[t-22]/22)))^2/22) 
}
sigma=sig[24:T]*100 

plot(log(pt[24:length(rte)]),type='l',col=2,axes=F,xlab="", ylab="",lwd=2)
axis(2,at=seq(0.5,5,by=0.1)) # axe de gauche
par(new=T)
plot(sigma, col="grey",type='l',axes = F,xlab="", ylab="")
axis(4,at=seq(0,8,by=0.25)) # axe de droite
legend("topleft", c("log(pt)","sigma"),col = c(2, 1),lty=c(1,1))
```

On voit que les p√©riodes de chute de march√© sont caract√©ris√©es par une augmentation de la volatilit√© sup√©rieur √† celle cons√©cutive √† une hausse des cours. Mais pas syst√©matiquement, on en conclut tout de m√™me √† la **pr√©sence d'effet de levier**.

## Propri√©t√© 7 : La saisonnalit√©

### 7.1 Effet week-end

Les march√©s financiers sont affect√©s par l‚Äôaccumulation d‚Äôinformation durant les p√©riodes de cl√¥ture du week-end ou encore durant les jours f√©ri√©s ou apr√®s les vacances. D‚Äôapr√®s French et Roll (1986), Baillie et Bollerslev (1989) la variance des rendements augmente √† partir du mercredi alors que d‚Äôapr√®s French et Roll (1986) elle est la plus forte le lundi.

```{r, echo=FALSE}
jour=format(dates[1:T], format = "%A")
tableaures <- data.frame(matrix(NA,ncol=5,nrow=4))
colnames(tableaures) <- c("Monday","Tuesday","Wednesday","Thursday","Friday")
rownames(tableaures) <- c("moyenne en %","√©cart-type annuel en %","skewness","kurtosis")

m<-seq(from=1,to=T,by=5)

rtmar<-as.numeric(rte[m])

rtmar<-as.numeric(rte[jour=="Tuesday"])
tuesday<-mean(rtmar) #moyenne journaliere
tableaures[1,2] <- tuesday*100 #moyenne journaliere en %
tableaures[2,2] <- sd(rtmar)*100*sqrt(252) #ecart-type annualise en %
tableaures[3,2] <- skewness(rtmar)
tableaures[4,2] <- kurtosis(rtmar)
rtmer<-as.numeric(rte[jour=="Wednesday"])
wednesday<-mean(rtmer)
tableaures[1,3] <- wednesday*100
tableaures[2,3] <- sd(rtmer)*100*sqrt(252)
tableaures[3,3] <- skewness(rtmer)
tableaures[4,3] <- kurtosis(rtmer)
rtjeu<-as.numeric(rte[jour=="Thursday"])
thursday<-mean(rtjeu)
tableaures[1,4] <- thursday*100
tableaures[2,4] <- sd(rtjeu)*100*sqrt(252)
tableaures[3,4] <- skewness(rtjeu)
tableaures[4,4] <- kurtosis(rtjeu)
rtven<-as.numeric(rte[jour=="Friday"])
friday<-mean(rtven)
tableaures[1,5] <- friday*100
tableaures[2,5] <- sd(rtven)*100*sqrt(252)
tableaures[3,5] <- skewness(rtven)
tableaures[4,5] <- kurtosis(rtven)
rtlun<-as.numeric(rte[jour=="Monday"])
monday<-mean(rtlun)
tableaures[1,1] <- monday*100
tableaures[2,1] <- sd(rtlun)*100*sqrt(252)
tableaures[3,1] <- skewness(rtlun)
tableaures[4,1] <- kurtosis(rtlun)
tableaures
```

Le lundi se caract√©rise par des rendements n√©gatifs et une skewness n√©gative, conform√©ment √† l'id√©e que l'accumulation d'informations durant le week-end entra√Æne une plus grande incertitude et une volatilit√© accrue, bien que l‚Äô√©cart-type soit mod√©r√© compar√© aux autres jours. Le jeudi appara√Æt comme le jour le plus volatil avec une skewness positive, ce qui sugg√®re qu‚Äôil y a plus d'opportunit√©s de rendements positifs, mais avec un risque plus √©lev√© d‚Äô√©v√©nements extr√™mes (kurtosis √©lev√©e). Bien que le vendredi ait un rendement moyen l√©g√®rement positif, la volatilit√© diminue par rapport au jeudi, mais reste plus √©lev√©e que le mercredi, ce qui refl√®te la cl√¥ture de la semaine.

Ces r√©sultats confirment les observations de French et Roll (1986) et de Baillie et Bollerslev (1989) : la volatilit√© est souvent plus importante le lundi, et elle tend √† augmenter au milieu de la semaine, avec des rendements plus stables en fin de semaine. **Nous sommes bien en pr√©sence d'un effet week-end**.

### 7.2 Effet janvier

```{r, echo=FALSE}
monthplot(rte, ylab="rendement",main="", cex.main=1,col.base=2,lwd.base=3)
abline(h = 0.0022,col = 3,lwd = 1)
```

Les moyennes des rendements semblent constantes sur l'ann√©e mise √† part une l√©g√®re baisse en janvier, juillet et d√©cembre. **Il ne semble donc pas y avoir d'effet janvier**.

Nous pouvons cependant trouver un √©cart √† la moyenne au mois de mars, on peut donc constater un **effet mars**.

## Propri√©t√© 8 : Stationnarit√©

### Dickey Fuller (DF)

#### ‚Ä¢ Sp√©cification Trend

Nous allons commencer par la sp√©cification *"trend"* qui consiste √† estimer par les MCO :

$$
\Delta y_t = (\rho - 1) y_{t-1} + \beta_0 + \beta_1 \text{tendance}_t + \epsilon_t
$$

puis √† tester :

$$
H_0 : \rho - 1 = 0 \text{ et } \beta_1 = 0 \quad vs \quad H_a : |\rho| < 1 \text{ et } \beta_1 \neq 0
$$

Nous testons d'abord la significativit√© de $\beta_1$ pour v√©rifier que la sp√©cification soit la bonne :

$$
H_0 : \beta_1 = 0 \quad vs \quad H_a : \beta_1 \neq 0
$$

L'hypoth√®se nulle est rejet√©e au risque $\alpha$ de 5% si la *p-value* associ√©e √† $\beta_1$ est inf√©rieure √† $\alpha$.

```{r, echo=FALSE}
summary(ur.df(rte,type= "trend",lags=0))
```

On voit que $\beta_1$ le coefficient associ√© √† la tendance nomm√©e `tt` dans R n‚Äôest pas significative (puisque sa p-value dans la colonne `Pr(>||)` dans R est sup√©rieur √† 0.05), on accepte donc H0. Cela implique que le processus qui a g√©n√©r√© les donn√©es ne pourra pas √™tre TS. On passe au mod√®le contenant une constante, mais pas de tendance.

#### ‚Ä¢ Sp√©cification Drift

La sp√©cification *"drift"* consiste √† estimer par les MCO :

$$
\Delta y_t = (\rho - 1) y_{t-1} + \beta_0 + \epsilon_t
$$

puis √† tester :

$$
H_0 : \rho - 1 = 0 \text{ et } \beta_0 = 0 \quad vs \quad H_a : |\rho| < 1 \text{ et } \beta_0 \neq 0
$$

Nous commen√ßons par tester la significativit√© de $\beta_0$ pour v√©rifier que la sp√©cification soit la bonne :

$$
H_0 : \beta_0 = 0 \quad vs \quad H_a : \beta_0 \neq 0
$$

L'hypoth√®se nulle est rejet√©e au risque $\alpha$ de 5% si la *p-value* associ√©e √† $\beta_0$ est inf√©rieure √† $\alpha$.

```{r, echo=FALSE}
summary(ur.df(rte,type= "drift",lags=0))
```

On voit $\beta_0$ la constante (nomm√©e `Intercept` dans R) n‚Äôest pas significative (0.16 > 0.05) donc on accepte H0 et cette r√©gression n‚Äôest pas la bonne.

#### ‚Ä¢ Sp√©cification None

```{r, echo=FALSE}
summary(ur.df(rte,type= "none",lags=0))
```

La `t calcul√©` = -40.81 < -1.95 donc on rejette H0. On en conclut que **le PGD est stationnaire**. 

Cette conclusion n‚Äôest valide que si les al√©as de la r√©gression de Dickey et Fuller ne sont pas auto-corr√©l√©s. V√©rifions cela maintenant :

```{r, echo=FALSE}
plot(ur.df(rte,lag=0,type="none"))
```

D‚Äôapr√®s l‚ÄôACF toutes les valeurs des coefficients d‚Äôautocorr√©lation semblent se situer dans l‚Äôintervalle de confiance mis √† part celle √† l‚Äôordre 0 et 7. **Il semble donc y avoir de l'autocorr√©lation**.

Dans la PACF, cela semble se confirmer, car l‚Äôensemble des coefficients d‚Äôautocorr√©lation partiels se situent dans l‚Äôintervalle de confiance mis √† part √† l'ordre 7.

**Nous devons donc effectuer un test de RU dans le cadre de la r√©gression ADF**.

### Dickey Fuller Augment√© (ADF)

Le test ADF correspond √† un test DF avec des variables explicatives en plus qui repr√©sentent la variable retard√©e jusqu‚Äô√† l‚Äôordre P : 

$$
\Delta y_t = (\rho - 1) y_{t-1} + \sum_{p=1}^{P} \gamma_p \Delta y_{t-p} + \epsilon_t
$$

La valeur de Pmax est calcul√©e par la formule de Schwert (1989) : $[12 \times (T/100)^0,25]$

```{r, echo=FALSE}
Schwert<-as.integer(12*(T/100)^(0.25))
cat("Le crit√®re de Schwert est calcul√© comme √©tant √©gal √†", Schwert, ".\n")
```

#### ‚Ä¢ MAIC

Nous devons maintenant minimiser le crit√®re d‚Äôinformation de Ng et Perron (2001), le $MAIC(p)$, calcul√© pour diff√©rentes valeurs de p allant de 0 √† Pmax (ici de 0 √† 26). Le $MAIC(p)$ est donn√© par la formule
suivante :

$$
MAIC(p) = \ln(\hat{\sigma}^2_p) + 2 \frac{(\tau_T(p)+p)}{T-Pmax}
$$

```{r, echo=FALSE}
summary(CADFtest(rte, criterion="MAIC",type="none",max.lag.y=Schwert))
```

`‚ÄúMax lag of the diff. dependent variable‚Äù` nous indique le nombre de variables explicatives √† ajouter pour tenir compte de l‚Äôautocorr√©lation. 

Nous avons ici `‚ÄúMax lag of the diff. dependent variable‚Äù` = 0, on doit donc faire le BIC.

#### ‚Ä¢ BIC

```{r, echo=FALSE}
summary(CADFtest(rte,criterion="BIC",type="none",max.lag.y=Schwert))
```

**_COURS :_** Si le MAIC et le BIC vous donnent `pmax = 0`, alors vous allez introduite pmax variables explicatives additionnelles dans la r√©gression puis √¥tez un par un les $\gamma$ qui ne sont pas significatifs jusqu‚Äô√† aboutir √† un mod√®le o√π le dernier $\gamma$ est significatif sachant qu‚Äôon s‚Äôaccorde √† dire que $\gamma$ est significatif si la valeur absolue de sa statistique $t > 1.6$. Vous pouvez ainsi aboutir √† un mod√®le avec `lag=3` car  $\gamma_1$ ni $\gamma_2$ ne le sont :

```{r echo=TRUE, results="hide"}
summary(ur.df(rte,type= "none",lags=Schwert))
summary(ur.df(rte,type= "none",lags=Schwert-1))
```

```{r, echo=TRUE}
summary(ur.df(rte,type= "none",lags=Schwert-2))
```

Avec un lag de 22, le dernier coefficient a comme valeur absolue de sa statistique test sup√©rieur √† 1.6, c'est donc significatif. Le dernier coefficient est sup√©rieur √† 1.6, c'est donc significatif. De plus, comme la statistique de test de -8.42 est bien plus basse que la valeur critique au seuil de 5 %, nous pouvons rejeter l'hypoth√®se nulle de racine unitaire (non-stationnarit√©). Sur la base des r√©sultats du test ADF, il semble que **la s√©rie `rte` test√©e est stationnaire**.

**_COURS :_** Selon Perron (1989), les tests DF et ADF auront tendance √† accepter H0 quand ils sont appliqu√©s √† une s√©rie stationnaire dont la tendance a subi un changement structurel.

### Zivot et Andrews (ZA)

Ici, nous r√©alisons la m√©thode d√©crite par Perron en 1989 qui consiste √† partir de la forme de Schwert puis de diminuer le nombre de $\gamma$ de tel sorte que le dernier ait une statistique t en valeur absolue < 1.6 et l'avant dernier une statistique t en valeur absolue sup√©rieur 1.6 : 

$$
H_0 : \rho = 1 \quad vs \quad H_a : |\rho| < 1 \
$$

```{r echo=TRUE, results="hide"}
summary(ur.za(rte, model="both",lag=24))
summary(ur.za(rte, model="both",lag=23))
summary(ur.za(rte, model="both",lag=22))
summary(ur.za(rte, model="both",lag=21))
summary(ur.za(rte, model="both",lag=20))
summary(ur.za(rte, model="both",lag=19))
summary(ur.za(rte, model="both",lag=18))
summary(ur.za(rte, model="both",lag=17))
summary(ur.za(rte, model="both",lag=16))
summary(ur.za(rte, model="both",lag=15))
summary(ur.za(rte, model="both",lag=14))
summary(ur.za(rte, model="both",lag=13))
summary(ur.za(rte, model="both",lag=12))
summary(ur.za(rte, model="both",lag=11))
summary(ur.za(rte, model="both",lag=10))
summary(ur.za(rte, model="both",lag=9))
summary(ur.za(rte, model="both",lag=8))
summary(ur.za(rte, model="both",lag=7))
summary(ur.za(rte, model="both",lag=6))
summary(ur.za(rte, model="both",lag=5))
summary(ur.za(rte, model="both",lag=4))
summary(ur.za(rte, model="both",lag=3))
```

**_NOTE :_** Nous ne pouvons pas rigoureusement dans notre cas appliquer la m√©thode de Perron. Car la condition n'est jamais atteinte. On prendra donc ici le mod√®le qui s'y rapproche le plus soit `lag = 2` :

```{r}
summary(ur.za(rte, model="both",lag=2))
```

On voit que :

- La statistique t en valeur absolue de $ùõæ1 = 1.571 ‚âÉ 1,6$

- La statistique t en valeur absolue de $ùõæ2 = 0.235 < 1,6$

- les coefficients $Œ¥1$ et $Œ¥2$ sont significatifs (ici `du` et `dt`)

La statistique de test est $-24.8727 < ‚àí5.08$ la valeur critique √† 5 %. On rejette donc H0.

**Cela pourrait nous amener √† penser que le PGD est TS avec un changement structurel**. Cependant, cette conclusion ne peut pas √™tre tir√©e de mani√®re d√©finitive. Il est aussi envisageable que le PGD soit DS avec un changement structurel.

La date de rupture est la 272e observation qui correspond √† la date :

```{r, echo=FALSE}
dates[272]
```

Nous pouvons constater la date de rupture sur le graphique ci-dessous :

```{r, echo=FALSE}
plot(ur.za(rte, model="both",lag=2))
```

> En janvier 2014, Square Enix avait commenc√© √† se redresser apr√®s plusieurs ann√©es difficiles dues √† des titres d√©cevants et des pertes financi√®res. En effet, en 2013, la soci√©t√© a publi√© plusieurs jeux √† succ√®s, dont "Final Fantasy XIV: A Realm Reborn", qui a √©t√© un succ√®s critique et commercial apr√®s l'√©chec de la version initial en 2010. Ce relancement a probablement soutenu les performances financi√®res de la soci√©t√©, stimulant ainsi la confiance des investisseurs. L'impact de ce redressement a pu se faire sentir au d√©but de 2014, expliquant cette date de rupture.

### Lee et Strazicich (LS)

Le test de Lee et Strazicich est une g√©n√©ralisation du test de racine unitaire de Schmidt et Phillips (SP). Ils ont g√©n√©ralis√© le test SP en employant la classification des changements structurels de Perron (1989) ‚Äùcrash‚Äù et ‚Äùboth‚Äù sachant qu‚Äôils les appellent respectivement ‚Äùcrash‚Äùet ‚Äùbreak‚Äù et en introduisant 2 dates de rupture endog√®nes. Le mod`ele est le suivant :

$$
y_t = \delta' Z_t + e_t
e_t = \beta e_{t-1} + \varepsilon_t
$$

avec $\varepsilon \sim \mathcal{N}(0,\sigma^2)$ et $Z$ la matrice des variables exog√®nes.

Soit $T_{B1}$ la date du premier changement structurel et $T_{B2}$ la date du second.

- ‚Äùcrash‚Äù : $Z_t = [\iota, tendance, DU_{1t}, DU_{2t}]'$ avec $DU_{jt} = 1$ si $t‚â•T_{Bj} + 1$ pour $j=1,2$ et $0$ sinon

- ‚Äùbreak‚Äù : $Z_t = [\iota, tendance, DU_{1t}, DU_{2t}, DT_{1t} , DT_{2t}]'$ avec $DT_{jt} = t- T_{Bj}$ si $t‚â•T_{Bj} + 1$ pour $j=1,2$ et $0$ sinon


Pour **"crash"**, nous testons : 

$$
H0 : y_t = \mu_0 + d_1 B_{1t} + d_2 B_{2t} + y_{t-1} + v_{1t}

VS

Ha : y_t = \mu_1 + \gamma \times trend_t + d_1 D_{1t} + d_2 D_{2t} + v_{2t}
$$

Pour **"break"**, nous testons : 

$$
H0 : y_t = \mu_0 + d_1 B_{1t} + d_2 B_{2t} + d_3 D_{1t} + d_4 D_{2t} + y_{t-1} + v_{1t}

VS

Ha : y_t = \mu_1 + \gamma \times trend_t + d_1 D_{1t} + d_2 D_{2t} + d_3 DT_{1t} + d_4 DT_{2t} + v_{2t}
$$

Notons que dans tous les cas, le PGD comprend des changements structurels sous H0 et sous Ha.

Le test LS peut s‚Äôeffectuer avec ou sans boostrap. Dans notre cas, nous n‚Äôutiliserons pas boostrap car ce
dernier est employ√© lorsque nous avons un faible nombre d‚Äôobservation. Ce qui n'est pas le cas pour notre s√©re `rte` (nombre de jour sup√©rieur √† 100). 

```{r, echo=FALSE}
#source("C:\\Users\\mlebreto\\Documents\\gretha\\2020-2021\\M1IREF\\LeeStrazicichUnitRoot-master(2)\\LeeStrazicichUnitRoot-master\\LeeStrazicichUnitRootTest.R")
source("/Users/alexandra/iref/s3/VaR/LeeStrazicichUnitRoot-master/LeeStrazicichUnitRootTest.R")
myBreaks <- 1
myModel <- "crash"
myLags <- Schwert
myLS_test <- ur.ls(y=rte , model = myModel, breaks = myBreaks, lags = myLags, method = "GTOS", pn = 0.1, print.results = "print")
```

`First possible structural break at position: 1525`

Cette position correspond √† la date : 

```{r, echo=FALSE}
dates[1525]
```

> Cette date de rupture peut avoir un lien avec un ralentissement temporaire apr√®s une p√©riode de grande anticipation. En effet, en janvier 2019, il y avait une grande attente autour de la sortie du jeu "Kingdom Hearts III", qui est finalement sorti le 25 janvier 2019. Souvent, lorsque la sortie d'un jeu tr√®s attendu approche, les investisseurs peuvent √™tre prudents, ce qui peut provoquer une baisse des actions en raison des incertitudes sur les critiques et les ventes r√©elles. Apr√®s le pic d'attente, certains investisseurs peuvent avoir d√©cid√© de prendre leurs b√©n√©fices, entra√Ænant une chute temporaire de l'action avant que les performances r√©elles ne soient connues.

La valeur de la statistique du test est -8.208032 ce qui est inf√©rieur √† la valeur critique -3.566. On rejette alors H0 ce qui nous permet de conclure que le PGD qui a g√©n√©r√© la s√©rie `rte` et donc il n‚Äôy a pas de racine unitaire.

De plus, le PGD ne peut pas √™tre TS puisque nous avons vu qu‚Äôil n‚Äôy a pas de tendance. **La conclusion est
que le PGD qui a g√©n√©r√© notre s√©rie est stationnaire avec une date de rupture en janvier 2019**.

# √âtude des 8 caract√©ristiques la s√©rie rtt

Voici le chronogramme de la s√©rie `rtt` : 

```{r, echo=FALSE}
# Supposons que rtt soit d√©j√† au format s√©rie temporelle
plot(rtt, main = "Chronogramme de la s√©rie rtt", xlab = "Temps", ylab = "Rendements", col = "#A4163E", type = "l")
```

La s√©rie `rtt` n'a visuellement pas l'air d'avoir de tendance, elle fluctue autour de 0. De plus, la variance semble diminuer au cours du temps, on d√©tectera sans doute de l'h√©t√©rosc√©dasticit√©.

## Propri√©t√© 1 : Asym√©trie perte / gain

### Hypoth√®ses

$H_0 : E\left[\left(\frac{X - E(X)}{\sigma_X}\right)^3\right] = 0 \quad VS \quad H_a : E\left[\left(\frac{X - E(X)}{\sigma_X}\right)^3\right] \neq 0$

### Cas pratique

```{r, echo=FALSE}
agostino.test(rtt)
```

Le coefficient du skewness n'est pas significatif puisque la p-value √©tant sup√©rieur 0.05 on accepte donc H0. La skewness est statistiquement nulle, **la distribution est sym√©trique**.

## Propri√©t√© 2 : Queues de distribution √©paisses

### Hypoth√®ses

$H_0 : E\left[\left(\frac{X - E(X)}{\sigma_X}\right)^4\right] = 3 \quad VS \quad H_a : E\left[\left(\frac{X - E(X)}{\sigma_X}\right)^4\right] \neq 3$

### Cas pratique

```{r, echo=FALSE}
anscombe.test(rtt)
```

La p-value du test d‚ÄôAnscombe √©tant `< 2.2e-16` est inf√©rieur √† 0.05 on rejette H0, ce qui indique que le kurtosis est significatif. Celui-ci vaut `16` > 3 la distribution est donc **leptokurtique**. Ainsi, les queues de distribution sont plus √©paisses que celles d‚Äôune loi normale centr√©e r√©duite.

## Propri√©t√© 3 : Autocorr√©lations des carr√©s des rendements fortes et faibles pour les rendements

### R√©alisation de l'ACF et de la PACF

```{r, echo=FALSE}
op<-par(mfrow=c(2,2))
Acf(rtt,main="ACF du rendement logarithmique") 
Pacf(rtt,main="PACF du rendement logarithmique") 
Acf(rtt^2,main="ACF du rendement logarithmique au carr√©") 
Pacf(rtt^2,main="PACF du rendement logarithmique au carr√©")
```

### R√©alisation de la statistique de Ljung-Box

#### Hypoth√®ses

$H0 ‚à∂ \rho(k) = 0$ pour k = 1 jusqu‚Äô√† K $\quad VS \quad H_a : \rho(k) \neq 0$ pour au moins une valeur de k comprise entre 1 et K

#### Cas pratique

##### ‚Ä¢ Autocorr√©lations des carr√©s des rendements $rtt^2$

```{r, echo=FALSE}
pvaluesrtt =rep(0,20)
pvaluesrtt2 =rep(0,20)
for (i in 1:25 ) {
  pvaluesrtt[i] = Box.test(rtt,lag=i,type="Ljung-Box")$p.value
  pvaluesrtt2[i] = Box.test(rtt^2,lag=i,type="Ljung-Box")$p.value
}

pvaluesrtt2
```

Toutes les p-values sont inf√©rieures √† 0.05 pour `rtt^2` √† part √† l'ordre 1. On rejette donc H0 et on conclut √† la **pr√©sence d‚Äôautocorr√©lation dans les rendements au carr√©**.

##### ‚Ä¢ Autocorr√©lations des rendements rtt

```{r, echo=FALSE}
pvaluesrtt
```

Les p-values aux ordres 4, 5 et toutes celles partir de 11 sont inf√©rieurs √† 0.05 pour `rtt`. On rejette donc H0 et on conclut qu'il y a **pr√©sence d'autocorr√©lation**.

Pour mod√©liser cette caract√©ristique, nous utiliserons un mod√®le ARMA(p,q) dont la mise en ≈ìuvre contient 3 √©tapes.

#### ‚Ä¢ √âtape 1 : D√©termination de p et p du ARMA(p,q) via l‚Äôeacf

```{r, echo=FALSE}
eacf(rtt)
```

On trouve p = 4 et q = 4.

#### ‚Ä¢ √âtape 2 : Estimation du mod√®le ARMA(p,q) avec les valeurs trouv√©es via l‚Äôeacf

##### Estimation du mod√®le ARMA(4,4)

```{r, echo=FALSE}
reg1<-Arima(rtt, order=c(4,0,4), fixed=c(NA,NA,NA,NA,NA,NA,NA,NA,NA))
coeftest(reg1)
```

Aucune p-value est significative. On enl√®ve les deux coefficients les plus √©lev√©s, c'est-√†-dire `ar3` et `ma3` :

```{r, echo=FALSE}
reg1<-Arima(rtt, order=c(4,0,4), fixed=c(NA,NA,0,NA,NA,NA,0,NA,NA))
coeftest(reg1)
```

Tous les coefficients ne sont pas significatifs. On enl√®ve l'`intercept` :

```{r, echo=FALSE}
reg1<-Arima(rtt, order=c(4,0,4),include.mean=F,fixed=c(NA,NA,0,NA,NA,NA,0,NA))
coeftest(reg1)
```

Seulement `ar4` n'est pas significatif, on l'enl√®ve : 

```{r, echo=FALSE}
reg1<-Arima(rtt, order=c(4,0,4),include.mean=F,fixed=c(NA,NA,0,0,NA,NA,0,NA))
coeftest(reg1)
```

Il ne reste plus que `ma4` qui √† une p-value inf√©rieur √† 0.05. On enl√®ve donc le coefficient donc la pvalue est la plus √©lev√©e, soit ici `ma1` :

```{r, echo=FALSE}
reg1<-Arima(rtt, order=c(4,0,4),include.mean=F,fixed=c(NA,NA,0,0,NA,NA,0,NA))
coeftest(reg1)
```

En proc√©dant toujours de la m√™me mani√®re, c'est-√†-dire en enlevant un √† un le coefficient dont la p-value est la plus √©lev√©e et sup√©rieur √† 0.05, on obtient :

```{r echo=TRUE, results="hide"}
reg1<-Arima(rtt, order=c(4,0,4),include.mean=F,fixed=c(0,NA,0,0,NA,NA,0,NA))
reg1<-Arima(rtt, order=c(4,0,4),include.mean=F,fixed=c(NA,NA,0,0,0,NA,0,NA))
reg1<-Arima(rtt, order=c(4,0,4),include.mean=F,fixed=c(NA,NA,0,0,0,0,0,NA))
```

```{r}
reg1<-Arima(rtt, order=c(4,0,4),include.mean=F,fixed=c(0,NA,0,0,0,0,0,NA))
coeftest(reg1)
```

Le mod√®le est correct, car tous les coefficients sont significatifs. On d√©termine maintenant sa valeur de BIC :

```{r echo=FALSE}
BIC(reg1)
```

Afin d'√™tre s√ªr que ce mod√®le est le meilleur nous avons tester d'autres mod√®les :

##### Estimation du mod√®le ARMA(3,3)

```{r echo=TRUE, results="hide"}
reg2<-Arima(rtt, order=c(3,0,3), fixed=c(NA,NA,NA,NA,NA,NA,NA))
reg2<-Arima(rtt, order=c(3,0,3), fixed=c(NA,0,NA,NA,NA,NA,NA))
reg2<-Arima(rtt, order=c(3,0,3),include.mean=F, fixed=c(NA,0,NA,NA,NA,NA))
```

```{r}
reg2<-Arima(rtt, order=c(3,0,3),include.mean=F, fixed=c(NA,0,NA,NA,NA,NA))
coeftest(reg2)
```

Le mod√®le est correct, car tous les coefficients sont significatifs. On d√©termine maintenant sa valeur de BIC :

```{r echo=FALSE}
BIC(reg2)
```

Le BIC associ√© √† l'ARMA(3,3) est sup√©rieur √† celui associ√© √† l'ARMA(4,4) on garde donc notre premier mod√®le pour l'instant. 

##### Estimation du mod√®le ARMA(1,1)

```{r echo=TRUE}
reg3 = Arima(rtt, order=c(1,0,1))
```

```{r}
reg3 = Arima(rtt, order=c(1,0,1),include.mean=F)
coeftest(reg3)
```

Le mod√®le est correct, car tous les coefficients sont significatifs. On d√©termine maintenant sa valeur de BIC :

```{r echo=FALSE}
BIC(reg3)
```

Le BIC associ√© √† l'ARMA(1,1) est sup√©rieur √† celui associ√© √† l'ARMA(4,4) on garde donc notre premier mod√®le pour l'instant. 

##### Estimation du mod√®le MA(13)

```{r echo=TRUE, results="hide"}
reg4<-Arima(rtt, order=c(0,0,13), fixed=c(NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,NA))
reg4<-Arima(rtt, order=c(0,0,13), fixed=c(NA,NA,NA,NA,0,NA,NA,NA,NA,0,NA,NA,NA,NA))
reg4<-Arima(rtt, order=c(0,0,13), fixed=c(NA,NA,0,NA,0,NA,NA,NA,0,0,NA,NA,NA,NA))
reg4<-Arima(rtt, order=c(0,0,13),include.mean=F,fixed=c(NA,NA,0,NA,0,NA,0,NA,0,0,NA,NA,NA))
reg4<-Arima(rtt, order=c(0,0,13),include.mean=F,fixed=c(0,NA,0,NA,0,NA,0,NA,0,0,NA,NA,NA))
reg4<-Arima(rtt, order=c(0,0,13),include.mean=F,fixed=c(0,NA,0,NA,0,NA,0,NA,0,0,NA,0,NA))
```

```{r}
reg4<-Arima(rtt, order=c(0,0,13),include.mean=F,fixed=c(0,NA,0,NA,0,0,0,0,0,0,NA,0,NA))
coeftest(reg4)
```

Le mod√®le est correct, car tous les coefficients sont significatifs. On d√©termine maintenant sa valeur de BIC :

```{r echo=FALSE}
BIC(reg4)
```

Le BIC associ√© √† l'MA(13) est sup√©rieur √† celui associ√© √† l'ARMA(4,4) on garde donc notre premier mod√®le. 

Ce mod√®le MA(4,4) sert √† mod√©liser l‚Äôautocorr√©lation d√©tect√©e dans `rtt`. Il y arrive si les coefficients sont significatifs et si les al√©as du mod√®le MA(5) ont une esp√©rance nulle et ne sont pas autocorr√©l√©es

#### ‚Ä¢ √âtape 3 : Les al√©as du mod√®le ont-ils une esp√©rance nulle et sont-ils non-autocorr√©l√©s ?

##### (a) Test d‚Äôesp√©rance nulle des al√©as du mod√®le MA sans la constante

$H0 ‚à∂ \mathbb{E}[\varepsilon] = 0 \quad VS \quad Ha ‚à∂ \mathbb{E}[\varepsilon] \neq 0$

```{r, echo=FALSE}
residu<-reg4$res
t.test(residu)
```

La p-value $= 0.78 > 0.05$ donc on accepte H0. On conclut donc que l‚Äôesp√©rance des al√©as est nulle et on passe au test d‚Äôabsence d‚Äôautocorr√©lation.

##### (b) Test d‚Äôabsence d‚Äôautocorr√©lation dans les al√©as du mod√®le ARMA

$H0$ : Absence d‚Äôautocorr√©lation jusqu‚Äô√† l‚Äôordre K $\quad VS \quad Ha$ : Pr√©sence d‚Äôautocorr√©lation

```{r, echo=FALSE}
residuv_rtt=(residu-mean(residu))/sd(residu)
K<-20
tmp<-rep(0,K)
for(i in 1:K){
  tmp[i]<-Box.test(residuv_rtt,lag=i,type="Ljung-Box")$p.value
}
tmp
```

Les p-values sont toutes sup√©rieures √† 0.05 donc on accepte H0 et on conclut qu‚Äôil n‚Äôy a pas d‚Äôautocorr√©lation dans les al√©as jusqu‚Äô√† l‚Äôordre 20.

## Propri√©t√© 4 : Clusters de volatilit√©

### Hypoth√®ses

$H0 ‚à∂ \alpha1 = \alpha2 = ... = \alpha m = 0$ donc homosc√©dasticit√© conditionnelle 

$VS$

$Ha ‚à∂ \alpha i \neq 0$ avec $i \neq 0$ donc h√©t√©rosc√©dasticit√© conditionnelle.

### Cas pratique

```{r, echo=FALSE}
LM1<-ArchTest(as.numeric(rtt),lag=1)
LM1
```

La p-value = 0.2286 est > 0.05, on accepte donc H0 et donc il y a absence de clusters de volatilit√© √† l‚Äôordre 1 dans `rtt`.

```{r, echo=FALSE}
LM2<-ArchTest(as.numeric(rtt),lag=2)
LM2
```

La p-value = 0.004902 est < 0.05, on rejette donc H0 et donc il y a pr√©sence de clusters de volatilit√© √† l‚Äôordre 2 dans `rtt`.

```{r, echo=FALSE}
LM20<-ArchTest(as.numeric(rtt),lag=20)
LM20
```

La p-value = 1.827e-06 < 0.05, on rejette donc H0. Il y a pr√©sence de clusters de volatilit√© dans `rtt`.

```{r, echo=FALSE}
LM30<-ArchTest(as.numeric(rtt),lag=30)
LM30
```

Les p-values sont quasi toutes inf√©rieures √† 0.05. On rejette donc H0. **Il y a donc des clusters de volatilit√© dans la s√©rie `rtt`**.

## Propri√©t√© 5 : Queues √©paisses conditionnelles

```{r, echo=FALSE}
volat<-garch(residuv_rtt,order=c(1,1)) 
summary(volat)
```

En proc√©dant de cette mani√®re, nous obtenons l'information `FALSE CONVERGENCE`. Pour rem√©dier √† cela, nous utilisons la fonction GarchFit :

```{r, echo=FALSE}
volat2=garchFit(residuv_rtt ~ garch(1,1), data=rtt, trace=F, include.mean = F)
summary(volat2)
```

```{r}
ArchTest(volat2@residuals,lag=1)
```

```{r}
ArchTest(volat2@residuals,lag=2)
```

```{r}
ArchTest(volat2@residuals,lag=20)
```

L'ensemble des p-value sont sup√©rieurs √† 0.05. On rejette donc H0. **On en conclut qu'il n'y a pas d'effet ARCH**.

Maintenant, on cherche √† voir si les queues de distribution des al√©as de notre ARMA-GARCH sont plus √©paisses que celles d‚Äôune loi normale.

$H0 ‚à∂$ kurtosis $= 3 \quad VS \quad Ha :$ kurtosis $\neq 3$

```{r, echo=FALSE}
anscombe.test(volat$res)
```

On trouve une p-value < 2.2e-16 donc on rejette H0. De plus, le kurtosis est sup√©rieur √† 3. Ainsi, les queues de distribution des al√©as de notre ARMA-GARCH sont plus √©paisses que celles d‚Äôune loi normale.

## Propri√©t√© 6 : Effet de levier

```{r, echo=FALSE}
sig<-rep(0,T2)
for(t in 1:T2) {
  sig[t]<-sqrt(sum(rtt[t-22]-(sum(rtt[t-22]/22)))^2/22) 
}
sigma=sig[24:T2]*100 

plot(log(pt[24:length(rtt)]),type='l',col=2,axes=F,xlab="", ylab="",lwd=2)
axis(2,at=seq(0.5,3.8,by=0.1))#axe de gauche
par(new=T)
plot(sigma, col="grey",type='l',axes = F,xlab="", ylab="")
axis(4,at=seq(0,3.8,by=0.1))#axe de droite
legend("topleft", c("log(pt)","sigma"),col = c(2, 1),lty=c(1,1))
```

On voit que les p√©riodes de chute de march√© sont caract√©ris√©es par une augmentation de la volatilit√© sup√©rieur √† celle cons√©cutive √† une hausse des cours. On en conclut tout de m√™me √† la **pr√©sence d'effet de levier**.

## Propri√©t√© 7 : La saisonnalit√©

### 7.1 Effet week-end

Les march√©s financiers sont affect√©s par l‚Äôaccumulation d‚Äôinformation durant les p√©riodes de cl√¥ture du week-end ou encore durant les jours f√©ri√©s ou apr√®s les vacances. D‚Äôapr√®s French et Roll (1986), Baillie et Bollerslev (1989) la variance des rendements augmente √† partir du mercredi alors que d‚Äôapr√®s French et Roll (1986) elle est la plus forte le lundi.

```{r, echo=FALSE}
jour=format(dates[1:T2], format = "%A")
tableaures <- data.frame(matrix(NA,ncol=5,nrow=4))
colnames(tableaures) <- c("Monday","Tuesday","Wednesday","Thursday","Friday")
rownames(tableaures) <- c("moyenne en %","√©cart-type annuel en %","skewness","kurtosis")

m<-seq(from=1,to=T2,by=5)

rtmar<-as.numeric(rtt[m])

rtmar<-as.numeric(rtt[jour=="Tuesday"])
tuesday<-mean(rtmar) #moyenne journaliere
tableaures[1,2] <- tuesday*100 #moyenne journaliere en %
tableaures[2,2] <- sd(rtmar)*100*sqrt(252) #ecart-type annualise en %
tableaures[3,2] <- skewness(rtmar)
tableaures[4,2] <- kurtosis(rtmar)
rtmer<-as.numeric(rtt[jour=="Wednesday"])
wednesday<-mean(rtmer)
tableaures[1,3] <- wednesday*100
tableaures[2,3] <- sd(rtmer)*100*sqrt(252)
tableaures[3,3] <- skewness(rtmer)
tableaures[4,3] <- kurtosis(rtmer)
rtjeu<-as.numeric(rtt[jour=="Thursday"])
thursday<-mean(rtjeu)
tableaures[1,4] <- thursday*100
tableaures[2,4] <- sd(rtjeu)*100*sqrt(252)
tableaures[3,4] <- skewness(rtjeu)
tableaures[4,4] <- kurtosis(rtjeu)
rtven<-as.numeric(rtt[jour=="Friday"])
friday<-mean(rtven)
tableaures[1,5] <- friday*100
tableaures[2,5] <- sd(rtven)*100*sqrt(252)
tableaures[3,5] <- skewness(rtven)
tableaures[4,5] <- kurtosis(rtven)
rtlun<-as.numeric(rtt[jour=="Monday"])
monday<-mean(rtlun)
tableaures[1,1] <- monday*100
tableaures[2,1] <- sd(rtlun)*100*sqrt(252)
tableaures[3,1] <- skewness(rtlun)
tableaures[4,1] <- kurtosis(rtlun)
tableaures
```

French et Roll (1986) observent que la variance des rendements est la plus forte le lundi. Cela correspond partiellement √† notre tableau, o√π l'√©cart-type du lundi est effectivement √©lev√© (38,19 %), bien que ce ne soit pas le plus √©lev√© compar√© √† d'autres jours (comme le jeudi avec 45,92 %). Cette variance √©lev√©e pourrait s'expliquer par l'accumulation d'informations durant le week-end, qui se r√©percute sur les prix des actifs au d√©but de la semaine, cr√©ant une plus grande incertitude et volatilit√©.

Baillie et Bollerslev (1989) soutiennent que la variance augmente √† partir du mercredi. Dans nos donn√©es, on observe que l'√©cart-type du mercredi (31,71 %) est effectivement plus faible que les autres jours, mais une forte hausse de la volatilit√© se manifeste √† partir du jeudi (45,92 %), ce qui pourrait √™tre li√© √† l'effet d'accumulation d'information au milieu de la semaine, entra√Ænant une instabilit√© accrue.

**Nous sommes bien en pr√©sence d'un effet week-end**

### 7.2 Effet janvier

```{r, echo=FALSE}
monthplot(rtt, ylab="rendement",main="", cex.main=1,col.base=2,lwd.base=3)
abline(h = 0.0022,col = 3,lwd = 1)
```

Les moyennes des rendements semblent constantes sur l‚Äôann√©e mise √† part une l√©g√®re baisse en f√©vrier et novembre Il ne semble donc pas y avoir d‚Äôeffet janvier.

Nous pouvons cependant trouver un √©cart √† la moyenne au mois de septembre o√π l'√©cart √† la moyenne est √©lev√© (n√©gativement), on peut donc constater un **effet septembre**.

## Propri√©t√© 8 : Stationnarit√©

Un processus stochastique {Xt} est stationnaire au second ordre si :

- $\mathbb{E}[X_t] = \mu$, une constante

- $Var(X_t) < \inf$

- $autocov(X_t,X_{t‚àís}) = \mathbb{E}[(X_t ‚àí \mu)(X_{t‚àís} ‚àí \mu)]= \gamma_s$ qui ne d√©pend que de s.

Un Bruit Blanc (BB) est une s√©quence de variables al√©atoires iid de moyenne nulle, de variance constante et non autocorr√©l√©es. Simulation d‚Äôun BB gaussien de moyenne nulle et d‚Äô√©cart-type 1 = tirage al√©atoire dans une normale centr√©e r√©suite

### Dickey Fuller (DF)

#### ‚Ä¢ Sp√©cification Trend

Nous allons commencer par la sp√©cification *"trend"* qui consiste √† estimer par les MCO :

$$
\Delta y_t = (\rho - 1) y_{t-1} + \beta_0 + \beta_1 \text{tendance}_t + \epsilon_t
$$

puis √† tester :

$$
H_0 : \rho - 1 = 0 \text{ et } \beta_1 = 0 \quad vs \quad H_a : |\rho| < 1 \text{ et } \beta_1 \neq 0
$$

Nous testons d'abord la significativit√© de $\beta_1$ pour v√©rifier que la sp√©cification soit la bonne :

$$
H_0 : \beta_1 = 0 \quad vs \quad H_a : \beta_1 \neq 0
$$

L'hypoth√®se nulle est rejet√©e au risque $\alpha$ de 5% si la *p-value* associ√©e √† $\beta_1$ est inf√©rieure √† $\alpha$.

```{r, echo=FALSE}
summary(ur.df(rtt,type= "trend",lags=0))
```

Tout d'abord, nous regardons la p-value associ√© √† $\beta1$ qui est > 0.05 (seuil de significativit√©). On en d√©duit que $\beta1$ n'est pas significatif. Alors la sp√©cification "trend" n'est pas la bonne et nous passons √† la sp√©cification "drift"

#### ‚Ä¢ Sp√©cification Drift

La sp√©cification *"drift"* consiste √† estimer par les MCO :

$$
\Delta y_t = (\rho - 1) y_{t-1} + \beta_0 + \epsilon_t
$$

puis √† tester :

$$
H_0 : \rho - 1 = 0 \text{ et } \beta_0 = 0 \quad vs \quad H_a : |\rho| < 1 \text{ et } \beta_0 \neq 0
$$

Nous commen√ßons par tester la significativit√© de $\beta_0$ pour v√©rifier que la sp√©cification soit la bonne :

$$
H_0 : \beta_0 = 0 \quad vs \quad H_a : \beta_0 \neq 0
$$

L'hypoth√®se nulle est rejet√©e au risque $\alpha$ de 5% si la *p-value* associ√©e √† $\beta_0$ est inf√©rieure √† $\alpha$.

```{r, echo=FALSE}
summary(ur.df(rtt,type= "drift",lags=0))
```

Tout d'abord, nous regardons la p-value associ√© √† $\beta0$ qui est > 0.05 (seuil de significativit√©). On en d√©duit que $\beta0$ n'est pas significatif. Alors la sp√©cification "drift" n'est pas la bonne et nous passons √† la sp√©cification "none"

#### ‚Ä¢ Sp√©cification None

La sp√©cification *"none"* consiste √† estimer par les MCO :

$$
\Delta y_t = (\rho - 1) y_{t-1} + \epsilon_t
$$

puis √† tester :

$$
H_0 : \rho - 1 = 0 \quad vs \quad H_a : |\rho| < 1
$$
Si on accept H0 alors le processus est DS sinon le processus est stationnaire.

```{r, echo=FALSE}
summary(ur.df(rtt,type= "none",lags=0))
```

Pour savoir si on accepte H0 ou non, la r√®gle de d√©cision est si la valeur de la statistique t associ√©e √† $(\rho - 1) >$ √† la valeur critique donn√©e √† l'intersection de la ligne tau 1 et de la colonne 5% on accepte H0.

Ici, la valeur de la statistique t associ√©e √† (rho - 1) est inf√©rieur √† la valeur critique. On rejette donc H0. **On en conclut donc que le PDG est stationnaire avec Dickey-Fuller**.

Cette conclusion n‚Äôest valide que si les al√©as de la r√©gression de Dickey Fuller ne sont pas auto-corr√©l√©s. V√©rifions cela maintenant :

```{r, echo=FALSE}
plot(ur.df(rtt,lag=0,type="none"))
```

Les conclusions du test DF ne sont valables que s'il n'y a pas d'autocorr√©lation. Or, ici, les al√©as sont autocorr√©l√©s donc notre conclusion n'est pas valide. **Nous devons donc effectuer le test de Dickey-Fuller Augment√© (ADF)**.

### Dickey-Fuller Augment√© (ADF)

Le test ADF correspond √† un test DF avec des variables explicatives en plus qui repr√©sentent la variable retard√©e jusqu‚Äô√† l‚Äôordre P : 

$$
\Delta y_t = (\rho - 1) y_{t-1} + \sum_{p=1}^{P} \gamma_p \Delta y_{t-p} + \epsilon_t
$$

La valeur de Pmax est calcul√©e par la formule de Schwert (1989) : $[12 \times (T/100)^0,25]$

```{r, echo=FALSE}
Schwert<-as.integer(12*(T2/100)^(0.25))
cat("Le crit√®re de Schwert est calcul√© comme √©tant √©gal √†", Schwert, ".\n")
```

#### ‚Ä¢ MAIC

Nous devons maintenant minimiser le crit√®re d‚Äôinformation de Ng et Perron (2001), le $MAIC(p)$, calcul√© pour diff√©rentes valeurs de p allant de 0 √† Pmax (ici de 0 √† 26). Le $MAIC(p)$ est donn√© par la formule
suivante :

$$
MAIC(p) = \ln(\hat{\sigma}^2_p) + 2 \frac{(\tau_T(p)+p)}{T-Pmax}
$$

```{r, echo=FALSE}
summary(CADFtest(rtt, criterion="MAIC",type="none",max.lag.y=Schwert))
```

On trouve `‚ÄúMax lag of the diff.dependent variable‚Äù` = 0, on doit donc faire le BIC.

#### ‚Ä¢ BIC

```{r, echo=FALSE}
summary(CADFtest(rtt,criterion="BIC",type="none",max.lag.y=Schwert))
```

On trouve `‚ÄúMax lag of the diff.dependent variable‚Äù` = 0, on doit donc partir de la valeur de Schwert.

**_COURS :_** Si le MAIC et le BIC vous donnent `pmax = 0`, alors vous allez introduite pmax variables explicatives additionnelles dans la r√©gression puis √¥tez un par un les $\gamma$ qui ne sont pas significatifs jusqu‚Äô√† aboutir √† un mod√®le o√π le dernier $\gamma$ est significatif sachant qu‚Äôon s‚Äôaccorde √† dire que $\gamma$ est significatif si la valeur absolue de sa statistique $t >1.6$. Vous pouvez ainsi aboutir √† un mod√®le avec `lag=3` car  $\gamma_1$ ni $\gamma_2$ ne le sont :

```{r}
summary(ur.df(rtt,type= "none",lags=Schwert))
```

Le dernier coefficient est sup√©rieur √† 1.6, c'est donc significatif. De plus, comme la statistique de test de -8.34 est bien plus basse que la valeur critique au seuil de 5 %, nous pouvons rejeter l'hypoth√®se nulle de racine unitaire (non-stationnarit√©). Sur la base des r√©sultats du test ADF, il semble que **la s√©rie `rtt` test√©e est stationnaire**.

### Zivot et Andrews (ZA)

Ici, nous r√©alisons la m√©thode d√©crite par Perron en 1989 qui consiste √† partir de la forme de Schwert puis de diminuer le nombre de $\gamma$ de telle sorte que le dernier ait une statistique t en valeur absolue < 1.6 et l'avant dernier une statistique t en valeur absolue sup√©rieure 1.6 :

$$
H_0 : \rho = 1 \quad vs \quad H_a : |\rho| < 1 \
$$

```{r echo=TRUE, results="hide"}
summary(ur.za(rtt, model="both",lag=22))
summary(ur.za(rtt, model="both",lag=21))
summary(ur.za(rtt, model="both",lag=20))
summary(ur.za(rtt, model="both",lag=19))
summary(ur.za(rtt, model="both",lag=18))
summary(ur.za(rtt, model="both",lag=17))
```

```{r}
summary(ur.za(rtt, model="both",lag=16))
```

On voit que :

- La statistique t en valeur absolue de $ùõæ15 = 1.967 > 1,6$

- La statistique t en valeur absolue de $ùõæ16 = 0.495 < 1,6$

- les coefficients $Œ¥1$ et $Œ¥2$ sont significatifs (ici `du` et `dt`)

La statistique de test est $-9.9161  < ‚àí5.08$ la valeur critique √† 5%. On rejette donc H0.

**Cela pourrait nous amener √† penser que le PGD est TS avec un changement structurel**. Cependant, cette conclusion ne peut pas √™tre tir√©e de mani√®re d√©finitive. Il est aussi envisageable que le PGD soit DS avec un changement structurel.

La date de rupture est la 164e observation qui correspond √† la date :

```{r, echo=FALSE}
dates[164]
```

Nous pouvons constater la date de rupture sur le graphique ci-dessous :

```{r, echo=FALSE}
plot(ur.za(rtt, model="both",lag=16))
```

> La date de rupture √©tant le 27 ao√ªt 2013, nous nous sommes int√©ress√©s √† l'actualit√© de l'√©poque chez Square Enix. Square Enix a connu une phase difficile entre 2010 et 2013, mais en 2013, la soci√©t√© a commenc√© √† voir des signes de redressement. La hausse en ao√ªt 2013 peut √™tre attribu√©e √† l'anticipation de la sortie imminente de "Final Fantasy XIV: A Realm Reborn", qui a √©t√© relanc√© le 27 ao√ªt 2013. Le jeu √©tait attendu avec impatience apr√®s l'√©chec de la version initiale, et la r√©ception positive du relancement a probablement contribu√© √† la hausse de l'action. Cela a marqu√© un tournant dans la r√©putation de Square Enix, qui commen√ßait √† regagner la confiance des joueurs et des investisseurs.

### Lee et Strazicich (LS)

Le test de Lee et Strazicich est une g√©n√©ralisation du test de racine unitaire de Schmidt et Phillips (SP). Ils ont g√©n√©ralis√© le test SP en employant la classification des changements structurels de Perron (1989) ‚Äùcrash‚Äù et ‚Äùboth‚Äù sachant qu‚Äôils les appellent respectivement ‚Äùcrash‚Äùet ‚Äùbreak‚Äù et en introduisant 2 dates de rupture endog√®nes. Le mod`ele est le suivant :

$$
y_t = \delta' Z_t + e_t
e_t = \beta e_{t-1} + \varepsilon_t
$$

avec $\varepsilon \sim \mathcal{N}(0,\sigma^2)$ et $Z$ la matrice des variables exog√®nes.

Soit $T_{B1}$ la date du premier changement structurel et $T_{B2}$ la date du second.

- ‚Äùcrash‚Äù : $Z_t = [\iota, tendance, DU_{1t}, DU_{2t}]'$ avec $DU_{jt} = 1$ si $t‚â•T_{Bj} + 1$ pour $j=1,2$ et $0$ sinon

- ‚Äùbreak‚Äù : $Z_t = [\iota, tendance, DU_{1t}, DU_{2t}, DT_{1t} , DT_{2t}]'$ avec $DT_{jt} = t- T_{Bj}$ si $t‚â•T_{Bj} + 1$ pour $j=1,2$ et $0$ sinon


Pour **"crash"**, nous testons : 

$$
H0 : y_t = \mu_0 + d_1 B_{1t} + d_2 B_{2t} + y_{t-1} + v_{1t}

VS

Ha : y_t = \mu_1 + \gamma \times trend_t + d_1 D_{1t} + d_2 D_{2t} + v_{2t}
$$

Pour **"break"**, nous testons : 

$$
H0 : y_t = \mu_0 + d_1 B_{1t} + d_2 B_{2t} + d_3 D_{1t} + d_4 D_{2t} + y_{t-1} + v_{1t}

VS

Ha : y_t = \mu_1 + \gamma \times trend_t + d_1 D_{1t} + d_2 D_{2t} + d_3 DT_{1t} + d_4 DT_{2t} + v_{2t}
$$

Notons que dans tous les cas, le PGD comprend des changements structurels sous H0 et sous Ha.

Le test LS peut s‚Äôeffectuer avec ou sans boostrap. Dans notre cas, nous n‚Äôutiliserons pas boostrap car ce
dernier est employ√© lorsque nous avons un faible nombre d‚Äôobservation. Ce qui n'est pas le cas pour notre s√©re `rtt` (nombre de jour sup√©rieur √† 100). 

```{r, echo=FALSE}
#source("C:\\Users\\mlebreto\\Documents\\gretha\\2020-2021\\M1IREF\\LeeStrazicichUnitRoot-master(2)\\LeeStrazicichUnitRoot-master\\LeeStrazicichUnitRootTest.R")
source("/Users/alexandra/iref/s3/VaR/LeeStrazicichUnitRoot-master/LeeStrazicichUnitRootTest.R")
myBreaks <- 1
myModel <- "crash"
myLags <- Schwert
myLS_test <- ur.ls(y=rtt , model = myModel, breaks = myBreaks, lags = myLags, method = "GTOS", pn = 0.1, print.results = "print")
```

`First possible structural break at position: 348`

Cette position correspond √† la date : 

```{r, echo=FALSE}
dates[348]
```

> La date de rupture √©tant le 21 mai 2014, nous nous sommes int√©ress√©s √† l'actualit√© de l'√©poque chez Square Enix. Cette p√©riode correspond √† un l√©ger creux apr√®s les premiers signes de redressement de Square Enix, probablement √† la suite de r√©sultats financiers ou d'√©v√©nements particuliers. Il n'y a pas eu de gros titres ou de jeux majeurs autour de mai 2014, ce qui pourrait indiquer que la baisse est li√©e √† une correction du march√© apr√®s une mont√©e pr√©c√©dente (comme celle de janvier 2014 √©voqu√© pr√©c√©demment) ou des attentes moins √©lev√©es pour les jeux √† venir. Les r√©sultats financiers publi√©s √† cette p√©riode auraient pu d√©cevoir, malgr√© le succ√®s des titres de 2013.

La valeur de la statistique du test est -9.659352 ce qui est inf√©rieur √† la valeur critique -3.566. On rejette alors H0 ce qui nous permet de conclure que le PGD qui a g√©n√©r√© la s√©rie `rtt` et donc il n‚Äôy a pas de racine unitaire.

De plus, le PGD ne peut pas √™tre TS puisque nous avons vu qu‚Äôil n‚Äôy a pas de tendance. **La conclusion est
que le PGD qui a g√©n√©r√© notre s√©rie est stationnaire avec une date de rupture en mai 2014**.

# Conclusion

Pour conclure, nous pouvons faire un tableau r√©capitulatif des r√©sultats pour les 8 caract√©ristiques de nos s√©ries `rte` et `rtt` :

```{r, echo=FALSE}
# Cr√©er une matrice avec les donn√©es des caract√©ristiques
data <- matrix(c(
  "OUI", "NON",       # Asym√©trie perte / gain
  "OUI P>G", "OUI P=G", # Queues de distribution √©paisses
  "NON", "OUI",       # Autocorr√©lations des carr√©s des rendements
  "OUI", "OUI",       # Clusters de volatilit√©
  "OUI", "OUI",       # Queues √©paisses conditionnelles
  "OUI", "OUI",       # Effet de levier
  "OUI", "OUI",       # Saisonnalit√©
  "OUI", "OUI"        # Stationnarit√©
), ncol = 2, byrow = TRUE)

# Ajouter les noms des colonnes et des lignes
colnames(data) <- c("RTE", "RTT")
rownames(data) <- c(
  "1. Asym√©trie perte / gain",
  "2. Queues de distribution √©paisses",
  "3. Autocorr√©lations des carr√©s des rendements",
  "4. Clusters de volatilit√©",
  "5. Queues √©paisses conditionnelles",
  "6. Effet de levier",
  "7. Saisonnalit√©",
  "8. Stationnarit√©"
)

# Afficher le tableau avec kable pour un rendu propre
kable(data, caption = "Tableau r√©capitulatif des caract√©ristiques pour RTE et RTT")
```

